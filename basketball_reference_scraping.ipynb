{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T01:48:25.942704Z",
     "start_time": "2019-11-17T01:48:25.939813Z"
    }
   },
   "outputs": [],
   "source": [
    "import pixiedust\n",
    "import requests, pandas as pd, numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T02:06:12.116648Z",
     "start_time": "2019-11-17T02:06:11.950434Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class boxScore:\n",
    "    # Date \n",
    "    def __init__(self, year = None, month = None, day = None):\n",
    "        '''\n",
    "        Input year, month, day as strings\n",
    "        '''\n",
    "        Someday = datetime.today() - timedelta(days = 200)\n",
    "        if year is None or month is None or day is None:\n",
    "            self.year = str(Someday.year)\n",
    "            self.month = \"0\" + str(Someday.month) if Someday.month < 10 else str(Someday.month)\n",
    "            self.sday = str(Someday.day)\n",
    "        else:\n",
    "            self.year = str(year)\n",
    "            self.month = \"0\" + str(month) if month < 10 else str(month)\n",
    "            self.day = \"0\" + str(day) if day < 10 else str(day)\n",
    "        self.my_date = self.year + \"-\" + self.month + \"-\" + self.day\n",
    "        \n",
    "        # 避免阻擋爬蟲\n",
    "        self.header = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'\n",
    "        }\n",
    "    \n",
    "    def PlayorNot(self):\n",
    "        # Check if there is no NBA game on the day?\n",
    "        \n",
    "        \n",
    "        url_games_played = \"https://www.basketball-reference.com/boxscores/?month=\" + self.month + \"&day=\" + self.day + \"&year=\" + self.year\n",
    "        page_games_played = requests.get(url_games_played, headers = self.header)\n",
    "        soup_games_played = BeautifulSoup(page_games_played.text, \"lxml\")\n",
    "        if soup_games_played.select(\"strong\")[1].text == \"No games played on this date.\":\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "            \n",
    "    def teamNameDictLong(self):\n",
    "        '''\n",
    "        This function is used to get the abbreviated team name on the website so that I can transform the full name on the game result.\n",
    "        Then, the abbreviation will help to get the url of box score.\n",
    "        '''\n",
    "\n",
    "        #Extract abbreviation of the team name from the website\n",
    "        month_dict = {\"10\": \"october\",\n",
    "                    \"11\": \"november\",\n",
    "                    \"12\": \"december\",\n",
    "                    \"01\": \"january\",\n",
    "                    \"02\": \"february\",\n",
    "                    \"03\": \"march\",\n",
    "                    \"04\": \"april\",\n",
    "                    \"05\": \"may\",\n",
    "                    \"06\": \"june\"}\n",
    "        \n",
    "        url_first = \"https://www.basketball-reference.com/leagues/NBA_\" + year + \"_games-\" + month_dict[month] +\".html\"\n",
    "        first_page = requests.get(url_first, headers = self.header)\n",
    "        soup_first = BeautifulSoup(first_page.text, 'lxml')\n",
    "        year_on_the_first_page = soup_first.select(\"#teams > h3\")[0].text\n",
    "        year_on_the_first_page = ''.join(list(map(year_on_the_first_page.__getitem__, [0, 1, 5, 6])))\n",
    "        \n",
    "        east_region = soup_first.select(\"#teams > div.data_grid.section_wrapper\")[0].find(\"tbody\").find_all(\"th\")\n",
    "        east_team = [re.search(r\"[A-Z]*\", team.text).group(0) for team in east_region]\n",
    "\n",
    "        west_region = soup_first.select(\"#confs_standings_W\")[0].find(\"tbody\").find_all(\"th\")\n",
    "        west_team = [re.search(r\"[A-Z]*\", team.text).group(0) for team in west_region]\n",
    "        abbr_team = east_team + west_team\n",
    "\n",
    "        #Extract the full team name from the website\n",
    "        url_full = \"https://www.basketball-reference.com/leagues/NBA_\" + year_on_the_first_page + \".html\"\n",
    "        page_full = requests.get(url_first, headers = self.header)\n",
    "        soup_full = BeautifulSoup(page_full.text, 'lxml')\n",
    "\n",
    "        east_team_full = [i.find_all('a')[0].get(\"title\") for i in \n",
    "                                 soup_full.select(\"#confs_standings_E > tbody\")[0].find_all(\"th\")]\n",
    "        \n",
    "        west_team_full = [i.find_all('a')[0].get(\"title\") for i in \n",
    "                                 soup_full.select(\"#confs_standings_W > tbody\")[0].find_all(\"th\")]\n",
    "                \n",
    "        full_team = east_team_full + west_team_full\n",
    "\n",
    "        return dict(zip(full_team, abbr_team))\n",
    "\n",
    "    def teamNameDictShort(self):\n",
    "        '''\n",
    "        This function is used to get the abbreviated team name on the website so that I can transform the full name on the game result.\n",
    "        Then, the abbreviation will help to get the url of box score.\n",
    "        '''\n",
    "\n",
    "        #Extract abbreviation of the team name from the website\n",
    "        url_first = \"https://www.basketball-reference.com\"\n",
    "        first_page = requests.get(url_first, headers = self.header)\n",
    "        soup_first = BeautifulSoup(first_page.text, 'lxml')\n",
    "        year_on_the_first_page = soup_first.select(\"#teams > h3\")[0].text\n",
    "        year_on_the_first_page = ''.join(list(map(year_on_the_first_page.__getitem__, [0, 1, 5, 6])))\n",
    "        \n",
    "        east_region = soup_first.select(\"#teams > div.data_grid.section_wrapper\")[0].find(\"tbody\").find_all(\"th\")\n",
    "        east_team = [re.search(r\"[A-Z]*\", team.text).group(0) for team in east_region]\n",
    "\n",
    "        west_region = soup_first.select(\"#confs_standings_W\")[0].find(\"tbody\").find_all(\"th\")\n",
    "        west_team = [re.search(r\"[A-Z]*\", team.text).group(0) for team in west_region]\n",
    "        abbr_team = east_team + west_team\n",
    "\n",
    "        #Extract the full team name from the website\n",
    "        url_full = \"https://www.basketball-reference.com/leagues/NBA_\" + year_on_the_first_page + \".html\"\n",
    "        page_full = requests.get(url_first, headers = self.header)\n",
    "        soup_full = BeautifulSoup(page_full.text, 'lxml')\n",
    "\n",
    "        east_team_full = [' '.join(i.find_all('a')[0].get(\"title\").split(' ')[:-1]) for i in \n",
    "                                 soup_full.select(\"#confs_standings_E > tbody\")[0].find_all(\"th\")]\n",
    "        \n",
    "        west_team_full = [i.find_all('a')[0].get(\"title\") for i in \n",
    "                                 soup_full.select(\"#confs_standings_W > tbody\")[0].find_all(\"th\")]\n",
    "        \n",
    "        # Special team name in west teams\n",
    "        for i in range(len(west_team)):\n",
    "            if west_team_full[i] ==  \"Portland Trail Blazers\":\n",
    "                west_team_full[i] = \"Portland \"\n",
    "            elif west_team_full[i] ==  \"Los Angeles Clippers\":\n",
    "                west_team_full[i] = \"LA Clippers \"\n",
    "            elif west_team_full[i] ==  \"Los Angeles Lakers\":\n",
    "                west_team_full[i] = \"LA Lakers \"\n",
    "        west_team_full = [' '.join(i.split(' ')[:-1]) for i in west_team_full]\n",
    "        \n",
    "        full_team = east_team_full + west_team_full\n",
    "\n",
    "        return dict(zip(full_team, abbr_team))\n",
    "    \n",
    "    def teamNameDictEasy(self):\n",
    "        return {'Philadelphia': 'PHI',\n",
    "         'Toronto': 'TOR',\n",
    "         'Miami': 'MIA',\n",
    "         'Boston': 'BOS',\n",
    "         'Cleveland': 'CLE',\n",
    "         'Orlando': 'ORL',\n",
    "         'Milwaukee': 'MIL',\n",
    "         'Charlotte': 'CHO',\n",
    "         #'Charlotte': 'CHA', #注意年份\n",
    "         'Atlanta': 'ATL',\n",
    "         'Detroit': 'DET',\n",
    "         'Washington': 'WAS',\n",
    "         'Brooklyn': 'BRK',\n",
    "         'Indiana': 'IND',\n",
    "         'Chicago': 'CHI',\n",
    "         'New York': 'NYK',\n",
    "         'Utah': 'UTA',\n",
    "         'Houston': 'HOU',\n",
    "         'Dallas': 'DAL',\n",
    "         'San Antonio': 'SAS',\n",
    "         'Minnesota': 'MIN',\n",
    "         'LA Lakers': 'LAL',\n",
    "         'LA Clippers': 'LAC',\n",
    "         'Phoenix': 'PHO',\n",
    "         'Portland': 'POR',\n",
    "         'Denver': 'DEN',\n",
    "         'Golden State': 'GSW',\n",
    "         'Memphis': 'MEM',\n",
    "         'New Orleans': 'NOP',\n",
    "         #'New Orleans': 'NOH', # 注意年份\n",
    "         'Oklahoma City': 'OKC',\n",
    "         'Sacramento': 'SAC',\n",
    "         'Seattle': 'SEA',\n",
    "         'New Jersey': 'NJN',\n",
    "         }\n",
    "    \n",
    "    # How many teams did play on the day?\n",
    "    def numberofTeamPlayedPerDay(self):\n",
    "        \n",
    "        url_games_played = \"https://www.basketball-reference.com/boxscores/?month=\" + str(self.month) + \"&day=\" + str(self.day) + \"&year=\" + str(self.year)\n",
    "        page_games_played = requests.get(url_games_played, headers = self.header)\n",
    "        soup_games_played = BeautifulSoup(page_games_played.text, \"lxml\")\n",
    "        \n",
    "        return int(soup_games_played.select(\"#content > div.section_heading > h2\")[0].text.split(\" \")[0])\n",
    "    \n",
    "    # Teams which played today\n",
    "    def whichTeamsPlayedPerDay(self):\n",
    "        ''' \n",
    "        This function is used to know what teams and how many teams played on a specific day. \n",
    "        It will return a list of team titles as abbreviation.\n",
    "        '''\n",
    "        url_games_played = \"https://www.basketball-reference.com/boxscores/?month=\" + str(self.month) + \"&day=\" + str(self.day) + \"&year=\" + str(self.year)\n",
    "\n",
    "        page_games_played = requests.get(url_games_played, headers = self.header)\n",
    "        soup_games_played = BeautifulSoup(page_games_played.text, \"lxml\")\n",
    "\n",
    "        team_one = []\n",
    "        team_two = []\n",
    "        for table in soup_games_played.find(\"div\", {\"class\": \"game_summaries\"}).find_all(\"table\", {\"class\": \"teams\"}):\n",
    "            team_one.append(table.find_all(\"tr\")[0].find(\"a\").text)\n",
    "            team_two.append(table.find_all(\"tr\")[1].find(\"a\").text)\n",
    "\n",
    "        for i in range(len(team_two)):\n",
    "            team_one[i] = self.teamNameDictEasy()[team_one[i]]\n",
    "            team_two[i] = self.teamNameDictEasy()[team_two[i]]\n",
    "\n",
    "        return team_one, team_two\n",
    "        \n",
    "    def extractTablesPerGame(self, index_of_game):\n",
    "        \n",
    "        team_one = self.whichTeamsPlayedPerDay()[0][index_of_game]\n",
    "        team_two = self.whichTeamsPlayedPerDay()[1][index_of_game]\n",
    "        url_box = \"https://www.basketball-reference.com/boxscores/\" + str(self.year) + str(self.month) + str(self.day) + \"0\" + team_two + \".html\"\n",
    "        date = datetime.strptime(\"-\".join([self.year, self.month, self.day]), \"%Y-%m-%d\").date()\n",
    "\n",
    "        # Preparing to scrape\n",
    "        web = requests.get(url_box, headers = self.header)\n",
    "        soup = BeautifulSoup(web.text, \"lxml\")\n",
    "\n",
    "\n",
    "        box_score = {\"Home\": [], \"Away\": []}\n",
    "\n",
    "        for tab in [team_one, team_two]:\n",
    "            \n",
    "            table_basic = soup.select(\"#box-\" + tab + \"-game-basic\")[0]\n",
    "            table_adv = soup.select(\"#box-\" + tab + \"-game-advanced\")[0]\n",
    "            \n",
    "            #Headers\n",
    "            headers =  [h.text for h in table_basic.find_all(\"tr\")[1].find_all(\"th\")]\n",
    "            headers[0] = \"Players\"\n",
    "            headers_advanced =  [h.text for h in table_adv.find_all(\"tr\")[1].find_all(\"th\")]\n",
    "            headers_advanced[0] = \"Players\"\n",
    "\n",
    "            # initializing empty list to store the statistics\n",
    "            empty_list_basic = []\n",
    "            empty_list_adv = []\n",
    "            \n",
    "            # Number of players in the table\n",
    "            num_of_players_played_basic = table_basic.find_all(\"td\", {\"data-stat\": \"mp\"}).__len__() - 1\n",
    "            num_of_players_played_adv = table_adv.find_all(\"td\", {\"data-stat\": \"mp\"}).__len__() - 1\n",
    "            \n",
    "            # Getting all the statistics\n",
    "            for player in list(range(0, 5)) + list(range(6, num_of_players_played_basic+1)):\n",
    "                empty_list_basic.append([ele.text for ele in table_basic.find(\"tbody\").find_all(\"tr\")[player]])\n",
    "\n",
    "            for player in list(range(0, 5)) + list(range(6, num_of_players_played_adv+1)):\n",
    "                empty_list_adv.append([ele.text for ele in table_adv.find(\"tbody\").find_all(\"tr\")[player]])\n",
    "\n",
    "            if tab == team_one:\n",
    "                box_score[\"Away\"] = pd.concat([pd.DataFrame(empty_list_basic, columns = headers),\n",
    "                                                             pd.DataFrame(empty_list_adv, columns = headers_advanced).iloc[:, 2:]],\n",
    "                                                             axis = 1)\n",
    "                box_score[\"Away\"].insert(0, \"Team\", [team_one] * num_of_players_played_basic) # Add team name\n",
    "                box_score[\"Away\"].insert(0, \"Home_Away\", [\"Away\"] * num_of_players_played_basic) # Add Home or Away\n",
    "            else:\n",
    "                box_score[\"Home\"] = pd.concat([pd.DataFrame(empty_list_basic, columns = headers),\n",
    "                                                               pd.DataFrame(empty_list_adv, columns = headers_advanced).iloc[:, 2:]],\n",
    "                                                               axis = 1)\n",
    "                box_score[\"Home\"].insert(0, \"Team\", [team_two] * num_of_players_played_basic) \n",
    "                box_score[\"Home\"].insert(0, \"Home_Away\", [\"Home\"] * num_of_players_played_basic)\n",
    "\n",
    "\n",
    "        # Merge the box scores of the home team and the away team\n",
    "        total_box_score = pd.concat([box_score[\"Home\"], box_score[\"Away\"]], sort = False)\n",
    "        total_box_score.insert(0, \"Date\", [self.my_date] * len(total_box_score)) # Add Date\n",
    "        total_box_score.insert(1, \"Game_Index\", [index_of_game + 1] * len(total_box_score)) # Add game index\n",
    "        total_box_score = total_box_score.applymap(lambda x: np.NaN if x == \"\" else x) # missing value \n",
    "        total_box_score.iloc[:, 6:40] = total_box_score.iloc[:, 6:40].applymap(lambda x: np.nan if x == np.nan else float(x)) # data types\n",
    "        total_box_score.reset_index(inplace = True, drop = True)\n",
    "        \n",
    "        return total_box_score\n",
    "    \n",
    "    def extractAllTablesPerDay(self):\n",
    "        '''\n",
    "        If there is no index of the game, I will scrape all the game played on that day.\n",
    "        If there is a specific index of the game, I will only scrape that game.\n",
    "        \n",
    "        The function returns two organized table as one basic and one advanced box score table\n",
    "        '''\n",
    "        # Information of the game\n",
    "\n",
    "        # I will save all the games played on that day in the dictionay\n",
    "        all_box_score = []\n",
    "        \n",
    "        number_of_games = self.numberofTeamPlayedPerDay()\n",
    "        for ind in range(number_of_games):\n",
    "            all_box_score.append(self.extractTablesPerGame(ind))\n",
    "            \n",
    "        \n",
    "        day_box_score = pd.concat(all_box_score, sort = False)\n",
    "        day_box_score.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        return day_box_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T20:20:48.215200Z",
     "start_time": "2019-11-16T20:20:48.212957Z"
    }
   },
   "outputs": [],
   "source": [
    "miss_date = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T03:22:57.185026Z",
     "start_time": "2019-11-17T02:15:27.971910Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Input the dates you want to search for \n",
    "    #start = input(\"Enter the first day (yyyy mm dd): \").replace(\" \", \"-\")\n",
    "    #end = input(\"Enter the last day (yyyy mm dd): \").replace(\" \", \"-\")\n",
    "    \n",
    "    # Transform the format\n",
    "    start = datetime.strptime(\"2014-10-1\", \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(\"2015-6-30\", \"%Y-%m-%d\")\n",
    "    date_generated = [start + timedelta(days=x) for x in range(0, (end-start).days + 1) if (start + timedelta(days=x)).month not in (7, 8, 9)]    \n",
    "    \n",
    "    \n",
    "    whole_table = []\n",
    "    for day in range(len(date_generated)):\n",
    "        try:\n",
    "            initialBoxScore = boxScore(date_generated[day].year,\n",
    "                                                   date_generated[day].month,\n",
    "                                                    date_generated[day].day)\n",
    "            time.sleep(np.random.randint(3, 7))\n",
    "\n",
    "            if initialBoxScore.PlayorNot() == 0:\n",
    "                continue\n",
    "\n",
    "            whole_table.append(initialBoxScore.extractAllTablesPerDay())\n",
    "        \n",
    "        except:\n",
    "            print(date_generated[day])\n",
    "            miss_date.append(date_generated[day])\n",
    "        \n",
    "    if whole_table == []:\n",
    "        print(\"No NBA games\")\n",
    "    else:\n",
    "        final_table = pd.concat(whole_table, sort = False)\n",
    "        final_table.reset_index(drop = True, inplace = True)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T03:41:06.660685Z",
     "start_time": "2019-11-17T03:41:05.983017Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#final_table.to_csv(\"table_14.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 196.79999387264252,
   "position": {
    "height": "218.39999389648438px",
    "left": "878px",
    "right": "20px",
    "top": "133px",
    "width": "252.39999389648438px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
